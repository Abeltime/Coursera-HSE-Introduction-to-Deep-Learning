{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7348d1a198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from preprocessed_mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "print(X_train.shape, y_train.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000,)\n",
      "(10000, 28, 28) (10000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50000)\n",
      "(784, 10000)\n",
      "(784, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the training, validate and test examples \n",
    "X_train_flatten = X_train.reshape(X_train.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "X_val_flatten = X_val.reshape(X_val.shape[0], -1).T\n",
    "X_test_flatten = X_test.reshape(X_test.shape[0], -1).T\n",
    "\n",
    "print(X_train_flatten.shape)\n",
    "print(X_val_flatten.shape)\n",
    "print(X_test_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    depth = tf.constant(C, name = \"C\")\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(labels, depth, axis = 0)\n",
    "    \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50000)\n",
      "(10, 10000)\n",
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "# encode y with one-hot\n",
    "y_train_one_hot = one_hot_matrix(y_train, 10)\n",
    "y_val_one_hot = one_hot_matrix(y_val, 10)\n",
    "y_test_one_hot = one_hot_matrix(y_test, 10)\n",
    "\n",
    "print(y_train_one_hot.shape)\n",
    "print(y_val_one_hot.shape)\n",
    "print(y_test_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 28 * 28 = 784)\n",
    "    n_y -- scalar, number of classes (from 0 to 9, so -> 10)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(tf.float32, [n_x, None], name = \"X\")\n",
    "    Y = tf.placeholder(tf.float32, [n_y, None], name = \"Y\")\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [50, 784]\n",
    "                        b1 : [50, 1]\n",
    "                        W2 : [10, 50]\n",
    "                        b2 : [10, 1]\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [50,784], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [50,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [10, 50], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [10,1], initializer = tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> SIGMOID -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z2 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z2, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z2 -- output of forward propagation (output of the last LINEAR unit), of shape (10, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z2\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z2)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- input target, of shape (10, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[:, k*mini_batch_size : (k+1)*mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k*mini_batch_size : (k+1)*mini_batch_size]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches*mini_batch_size : ]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches*mini_batch_size : ]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_val, Y_val, learning_rate = 0.0001,\n",
    "          num_epochs = 1000, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a two-layer tensorflow neural network: LINEAR->SIGMOID->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 784, number of training examples = 50000)\n",
    "    Y_train -- training set, of shape (output size = 10, number of training examples = 50000)\n",
    "    X_val -- validation set, of shape (input size = 784, number of validation examples = 10000)\n",
    "    Y_val -- validation set, of shape (output size = 10, number of validation examples = 10000)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z2 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z2, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "            \n",
    "            # Early stoping condition \n",
    "            #if np.absolute(costs[-1] - epoch_cost) < 1e-12:\n",
    "            #    break\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z2), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Validation Accuracy:\", accuracy.eval({X: X_val, Y: Y_val}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.858143\n",
      "Cost after epoch 100: 0.021193\n",
      "Cost after epoch 200: 0.002178\n",
      "Cost after epoch 300: 0.000095\n",
      "Cost after epoch 400: 0.000002\n",
      "Cost after epoch 500: 0.000000\n",
      "Cost after epoch 600: 0.000000\n",
      "Cost after epoch 700: 0.000000\n",
      "Cost after epoch 800: 0.000000\n",
      "Cost after epoch 900: 0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuYHHWd7/H3p3tyvw25ALlBAgYwyEUNBM4RxUW5eYko\nKgoiKAfjirq6+yiurou67vHG7uoCBlTAG+IFhMiJILgLiAomYRMgxEAIBJJwGUJCyIUkM/M9f1T1\nUAzdPZOQmu5JfV7P0093/7q6+ts1Pf3p+lXVrxQRmJmZAZQaXYCZmTUPh4KZmXVxKJiZWReHgpmZ\ndXEomJlZF4eCmZl1cSjYbkHSbyV9sNF1mPV3DgV7WSQ9IulNja4jIk6KiB82ug4ASbdKOqcPXmeQ\npMslbZD0hKRP9zD9+yWtlLRJ0nWSRvd2XpIOl7RQ0ub0+vDMY6+SdJOkpyX5wKd+zqFgTU9SS6Nr\nqGimWoALgGnAvsAbgc9IOrHahJIOBi4FPgDsBWwGLunNvCQNBK4HfgLsAfwQuD5tB9gO/AL48K57\na9YwEeGLLzt9AR4B3lTjsbcCi4D1wJ+AQzOPnQ88BDwH3A+cknnsLOCPwL8Da4F/SdvuAL4FrAMe\nBk7KPOdW4JzM8+tNOxW4PX3tW4CLgZ/UeA/HAquAzwJPAD8m+WK8AWhL538DMCmd/qtAB/A8sBG4\nKG0/CLgZeAZYBrxnFyz7NcDxmftfBq6uMe2/Aldl7u8PbANG9DQv4HhgNaDM448CJ3Z7jVckXymN\n/1z6svMXrylYLiS9Grgc+AgwhuRX6lxJg9JJHgKOAUYBXwJ+Iml8ZhYzgRUkv2q/mmlbBowFvgH8\nQJJqlFBv2quAv6R1XUDy67mevYHRJL+izyVZw74ivb8PsAW4CCAiPg/8ATgvIoZHxHmShpEEwlXA\nnsBpwCWSpld7MUmXSFpf43JPOs0ewHhgceapi4GDa7yHg7PTRsRDwFbggF7M62Dgnki/+XvxWtaP\nORQsL+cCl0bEXRHREUl//1bgKICI+GVErImIzoj4OfAgcGTm+Wsi4j8joj0itqRtKyPiexHRQdKF\nMZ4kNKqpOq2kfYAjgC9GxLaIuAOY28N76QT+OSK2RsSWiFgbEddExOaIeI4ktN5Q5/lvBR6JiCvS\n9/M/wDXAu6tNHBF/GxGtNS6HppMNT6+fzTx1AzCiRg3Du02bnb6nedV7ru1mHAqWl32Bv8/+ygUm\nAxMAJJ0paVHmsVeR/KqveKzKPJ+o3IiIzenN4VWmqzftBOCZTFut18pqi4jnK3ckDZV0abrRdgNJ\nV1SrpHKN5+8LzOy2LE4nWQPZWRvT65GZtlEkXWK1ph/Zra0yfU/zqvdc2804FCwvjwFf7fYrd2hE\n/EzSvsD3gPOAMRHRCtwHZLuC8tqL5XFgtKShmbbJPTyney1/DxwIzIyIkcDr03bVmP4x4LZuy2J4\nRHy02otJmiNpY43LEoCIWJe+l8MyTz0MWFLjPSzJTitpf2Ag8EAv5rUEOLRbV92hdV7L+jGHgu0K\nAyQNzlxaSL70Z0uaqcQwSW+RNAIYRvLF2QYg6WySNYXcRcRKYAFwgaSBko4G3raDsxlBsh1hfbpb\n5z93e/xJYL/M/RtI+u4/IGlAejlC0itr1Dg7DY1ql2w//o+AL0jaI53X/wGurFHzT4G3STom3cbx\nFeDatPurp3ndSrLx/BPprqufIPn7/RdA+vcdTBIypJ+ByrYj62ccCrYrzCP5kqxcLoiIBSRfLBeR\n7KGznGSvICLifuBC4M8kX6CHkOxt1FdOB47mhT2bfk6yvaO3/gMYAjwN3Anc2O3xbwOnSlon6Tvp\nF+/xJBuY15B0bX0deLlfnP9MssF+JckX9zcioquWdM3iGICIWALMJgmHp0iC+W97M6+I2Aa8AziT\nZE+ys4B3pO2QdI9t4YU1hy0kG/mtH9KLdygwKx5JPwf+GhHdf/GbFY7XFKxw0q6b/SWV0gO0ZgHX\nNbous2bQTEdnmvWVvYFrSY5TWAV8NN1N1Kzw3H1kZmZd3H1kZmZd+l330dixY2PKlCmNLsPMrF9Z\nuHDh0xExrqfp+l0oTJkyhQULFjS6DDOzfkXSyt5M5+4jMzPr4lAwM7MuDgUzM+viUDAzsy4OBTMz\n6+JQMDOzLg4FMzPrUphQWPbEc1z4u2U8vXFHRkg2MyuWwoTC8qc28p//tZy1G7f1PLGZWUEVJhTK\n6Tvt9ACAZmY1FSYUKqeX7eh0KJiZ1VKYUCinoeA1BTOz2ooTCqVKKDS4EDOzJlaYUEhXFNx9ZGZW\nR2FC4YU1BYeCmVktxQkFb2g2M+tRYUKh5DUFM7MeFScUKnsfdTa4EDOzJpZrKEg6UdIyScslnV/l\n8VGSfiNpsaQlks7Oq5bKwWsdXlMwM6spt1CQVAYuBk4CpgPvkzS922QfA+6PiMOAY4ELJQ3Mo56S\nj1MwM+tRnmsKRwLLI2JFRGwDrgZmdZsmgBFKDjceDjwDtOdRzAvdRw4FM7Na8gyFicBjmfur0ras\ni4BXAmuAe4FPRkQuvf6VXVK995GZWW2N3tB8ArAImAAcDlwkaWT3iSSdK2mBpAVtbW079ULuPjIz\n61meobAamJy5PyltyzobuDYSy4GHgYO6zygiLouIGRExY9y4cTtVjIe5MDPrWZ6hMB+YJmlquvH4\nNGBut2keBY4DkLQXcCCwIo9iSh7mwsysRy15zTgi2iWdB9wElIHLI2KJpNnp43OArwBXSroXEPDZ\niHg6j3p88JqZWc9yCwWAiJgHzOvWNidzew1wfJ41VHjobDOznjV6Q3OfKXWNfdTgQszMmlhxQqFy\nOk5vUzAzq6kwoeChs83MelacUKh0HzkUzMxqKkwoyMNcmJn1qDCh4GEuzMx6VpxQkI9oNjPrSWFC\nQZW9j7xNwcyspsKEgs/RbGbWs+KEggfEMzPrUWFCwUNnm5n1rEChkFy7+8jMrLbChIJ3STUz61lh\nQkESEoS7j8zMaipMKECyXcHDXJiZ1VaoUChLHjrbzKyOQoVCqeTuIzOzegoVCsmagkPBzKyWQoWC\ntymYmdVXrFAoyUNnm5nVUahQKJfkYS7MzOooVCiU5DOvmZnVU7BQcPeRmVk9hQqFpPvIoWBmVkuh\nQqHkg9fMzOoqViiUPHS2mVk9hQoFH7xmZlZfoUKh5G0KZmZ1FSsU5FAwM6unUKHg7iMzs/oKFQol\nH9FsZlZXoUKhXMIHr5mZ1VGoUPAoqWZm9RUuFLyiYGZWW6FCoeyhs83M6ipUKJSE9z4yM6ujYKHg\nbQpmZvUUKhTKJREOBTOzmnINBUknSlomabmk82tMc6ykRZKWSLotz3rKJR+8ZmZWT0teM5ZUBi4G\n3gysAuZLmhsR92emaQUuAU6MiEcl7ZlXPenr0eFMMDOrKc81hSOB5RGxIiK2AVcDs7pN837g2oh4\nFCAinsqxHsrC3UdmZnXkGQoTgccy91elbVkHAHtIulXSQklnVpuRpHMlLZC0oK2tbacLcveRmVl9\njd7Q3AK8FngLcALwT5IO6D5RRFwWETMiYsa4ceN2+sXkAfHMzOrKbZsCsBqYnLk/KW3LWgWsjYhN\nwCZJtwOHAQ/kUVDZQ2ebmdWV55rCfGCapKmSBgKnAXO7TXM98DpJLZKGAjOBpXkVVPYoqWZmdeW2\nphAR7ZLOA24CysDlEbFE0uz08TkRsVTSjcA9QCfw/Yi4L6+aSh7mwsysrjy7j4iIecC8bm1zut3/\nJvDNPOuoKAkf0WxmVkejNzT3KW9TMDOrr1ChkHQfNboKM7PmVaxQ8CipZmZ1FSoUyiWPkmpmVk+h\nQqEkj5JqZlZPoULBw1yYmdVXqFAoeZgLM7O6ChcK7j0yM6utUKFQLvngNTOzegoVCu4+MjOrr1ih\nUHL3kZlZPYUKhbJ8nIKZWT2FCoWSd0k1M6urWKGg5NrDZ5uZVVeoUCgrSQWPlGpmVl2hQqGUrip4\nu4KZWXXFCoXKmoKHzzYzq6pQoVBO3627j8zMqitUKFTWFNx9ZGZWXaFCoVyqdB85FMzMqilUKHSt\nKTgUzMyqKlYoVNYUnAlmZlUVKhR8nIKZWX2FCoXKEc3uPjIzq65YoVDymoKZWT29CgVJ7+5NW7Mr\n++A1M7O6erum8LletjW1soe5MDOrq6Xeg5JOAk4GJkr6TuahkUB7noXlQd6mYGZWV91QANYAC4C3\nAwsz7c8Bn8qrqLxU1hTCawpmZlXVDYWIWAwslnRVRGwHkLQHMDki1vVFgbtS2cNcmJnV1dttCjdL\nGilpNHA38D1J/55jXbnoGjrb3UdmZlX1NhRGRcQG4J3AjyJiJnBcfmXlozLMhVcUzMyq620otEga\nD7wHuCHHenJVGTrbawpmZtX1NhS+DNwEPBQR8yXtBzyYX1n58NDZZmb19bT3EQAR8Uvgl5n7K4B3\n5VVUXl7oPnIomJlV09sjmidJ+rWkp9LLNZIm5V3crtZ18JqPaDYzq6q33UdXAHOBCenlN2lbv+Lz\nKZiZ1dfbUBgXEVdERHt6uRIY19OTJJ0oaZmk5ZLOrzPdEZLaJZ3ay3p2StkD4pmZ1dXbUFgr6QxJ\n5fRyBrC23hMklYGLgZOA6cD7JE2vMd3Xgd/tWOk7rjJ0tkPBzKy63obCh0h2R30CeBw4FTirh+cc\nCSyPiBURsQ24GphVZbqPA9cAT/Wylp3mg9fMzOrbkV1SPxgR4yJiT5KQ+FIPz5kIPJa5vypt6yJp\nInAK8N16M5J0rqQFkha0tbX1suSX8pnXzMzq620oHJod6ygingFevQte/z+Az0ZE3f2BIuKyiJgR\nETPGjetxU0ZNJZ9Pwcysrl4dpwCUJO1RCYZ0DKSenrsamJy5Pylty5oBXK3ky3oscLKk9oi4rpd1\n7ZBS5YhmrymYmVXV21C4EPizpMoBbO8GvtrDc+YD0yRNJQmD04D3ZyeIiKmV25KuBG7IKxAgs/eR\ntymYmVXV2yOafyRpAfA3adM7I+L+Hp7TLuk8kuExysDlEbFE0uz08Tkvo+6d4qGzzczq6+2aAmkI\n1A2CKs+ZB8zr1lY1DCLirB2Z985Q14bmvF/JzKx/6u2G5t2Cu4/MzOorVih4mAszs7oKFQryEc1m\nZnUVKhQ89pGZWX2FDAUPnW1mVl2hQsFnXjMzq69goZBc+8xrZmbVFSoUyh4l1cysrkKFgofONjOr\nr1ihkG5TcO+RmVl1hQoFj31kZlZfoUKha+hsdx+ZmVVVqFDoOvOaQ8HMrKpChULJo6SamdVVrFAo\neZuCmVk9hQoFSI5VcPeRmVl1hQuFkjwgnplZLQUMBbn7yMyshsKFgruPzMxqK14oSN77yMyshsKF\nguSD18zMailcKJRL8oZmM7MaChkKXlMwM6uucKEgb1MwM6upcKFQlvc+MjOrpXihUPJxCmZmtRQu\nFEolH9FsZlZL8ULB3UdmZjUVLhTKEh3OBDOzqgoXCiUPc2FmVlPxQsGjpJqZ1VTAUPDBa2ZmtRQu\nFAaUS2zv6Gx0GWZmTalwoTB2+EDaNm5tdBlmZk2pcKEwoXUIa9Y/3+gyzMyaUiFD4ZlN29iyraPR\npZiZNZ0ChsJgANY8u6XBlZiZNZ9cQ0HSiZKWSVou6fwqj58u6R5J90r6k6TD8qwHYMKoIQA87i4k\nM7OXyC0UJJWBi4GTgOnA+yRN7zbZw8AbIuIQ4CvAZXnVUzGhNQmFNeu9pmBm1l2eawpHAssjYkVE\nbAOuBmZlJ4iIP0XEuvTuncCkHOsBYK+Rg5FgtUPBzOwl8gyFicBjmfur0rZaPgz8ttoDks6VtEDS\ngra2tpdV1MCWEuOGD+Jxb1MwM3uJptjQLOmNJKHw2WqPR8RlETEjImaMGzfuZb+ed0s1M6suz1BY\nDUzO3J+Utr2IpEOB7wOzImJtjvV0mdg6xNsUzMyqyDMU5gPTJE2VNBA4DZibnUDSPsC1wAci4oEc\na3mR8aMGs+bZLYQHxjMze5GWvGYcEe2SzgNuAsrA5RGxRNLs9PE5wBeBMcAlkgDaI2JGXjVVTGgd\nwvPbO1m3eTujhw3M++XMzPqN3EIBICLmAfO6tc3J3D4HOCfPGqqp7Ja6et0Wh4KZWUZTbGjua9P2\nGg7A0ic2NLgSM7PmUshQmDpmGMMHtXDvqmcbXYqZWVMpZCiUSuJVE0dyz2qHgplZViFDAeCQiaNY\n+vgGn3DHzCyjuKEwqZVt7Z088ORzjS7FzKxpFDYUDp04CsDbFczMMgobCvuOGcqIwS3ermBmllHY\nUJDE4ZNbWfjIup4nNjMriMKGAsAx08ay7MnnPA6SmVmq0KFw7IF7AnDbAy9vOG4zs91FoUNh2p7D\nmdg6hFuXPdXoUszMmkKhQ0ESbzhwHHc8+DTb2n28gplZoUMB4I0H7smmbR3c9XCfnMrBzKypFT4U\njpk2llFDBvCLBasaXYqZWcMVPhQGDyhzyqsnctN9T/DMpm2NLsfMrKEKHwoA7ztyH7Z1dHLt3V5b\nMLNicygAB+49glfv08qP71xJuwfIM7MCcyikPvqG/Vm5djPXeG3BzArMoZB68/S9OGxyK9/5/XK2\ntnc0uhwzs4ZwKKQk8Q/HH8Dq9Vu44o+PNLocM7OGcChkHDNtHG965V58+5YHWbVuc6PLMTPrcw6F\nbr4062Ak+Kfr7qOzMxpdjplZn3IodDOxdQifPfEg/ntZG9+97aFGl2Nm1qccClWcefS+zDp8At/6\n3TJuuf/JRpdjZtZnHApVSOJr7zyUQyaO4mNX3c2CR55pdElmZn3CoVDDkIFlrjjrCCa0DuHsK+Yz\n38FgZgXgUKhjzPBB/OScmYwbMYgP/OAubrzv8UaXZGaWK4dCDya2DuGXs4/mwL1HMvsnd/N/f7vU\nQ2GY2W7LodALY4YP4hcfOYozjtqHS29bwenfv4snNzzf6LLMzHY5h0IvDWop8y/vOIR/e89hLF61\nnuMuvI3L73jYaw1mtltxKOygd75mEjd+8vW8dt89+PIN9/O2i/7IHQ8+TYQPdDOz/s+hsBOmjB3G\nlWcfwZwzXsP6zds44wd38baL7mDu4jVeczCzfk397RfujBkzYsGCBY0uo8vz2zu47n9Wc9ntK1jx\n9CYm7TGEc143lVNeM4lRQwY0ujwzMwAkLYyIGT1O51DYNTo7g5uXPsmltz3E3Y+uZ2BLiRMO3ptT\nXzuJ/7X/GAaUvVJmZo3T21Bo6YtiiqBUEiccvDcnHLw396xaz68WruL6RWv4zeI1jBoygONeuSfH\nT9+Lo/cf6zUIM2taXlPI0db2Dm5d1sZNS57g90uf4tkt25Fg+viRHLXfGGZOHc0RU0azx7CBjS7V\nzHZz7j5qMts7Olm4ch13rljLXSueYeGj69jWnmyUntg6hIMnjOTgCaM4eMJIXrHncCbuMcRdTma2\nyzRF95GkE4FvA2Xg+xHxtW6PK338ZGAzcFZE3J1nTY0yoFziqP3GcNR+Y4BkLWLRo+tZ9Nh67luz\ngSVrnuXmpU9SyehySUxsHcK+Y4Yml9HDGN86mD1HDGbciEGMGzGI4YPc+2dmu1Zu3yqSysDFwJuB\nVcB8SXMj4v7MZCcB09LLTOC76fVub1BLmZn7jWFmGhIAm7a2s/TxDTz89CZWrt3Mymc2s3LtJuYu\nWsOG59tfMo+hA8tJQAwfxNjhgxg+uIVhA8sMHZReD2xh+KAWhg4qM2xgC0MHlhk2qIXBA0oMKJdo\nKZcYUBIt5RItZTGglFy3lESS12ZWNHn+1DwSWB4RKwAkXQ3MArKhMAv4USR9WHdKapU0PiIKOfLc\nsEEtzJgymhlTRr/ksfWbt/HEhudpe24rT23YStvGrcnt57bS9tzzLG/byOat7Wza1sGmre20v8yz\nxrWUREtZlJUEhAApGVZcAgGl9DaIktLHSdpKaagobS91zSO5pkkyp0nKaJoQbo4qrJb3HjGZc47Z\nL9fXyDMUJgKPZe6v4qVrAdWmmQi8KBQknQucC7DPPvvs8kL7g9ahA2kdOpCD9u7d9NvaO9m8LQmJ\nSlhUrrds76C9o5P2jmB7Z3rd0Ul7Z7C9vZPtnZE83hl0dAYREKTXEQR0tXUGaZdX0NmZmQ7oTG8k\n06fTprebQXNUQdMUEs1SiNU0dvig3F+jX3RKR8RlwGWQbGhucDn9wsCWEgNbBtI6tNGVmFl/kufu\nLauByZn7k9K2HZ3GzMz6SJ6hMB+YJmmqpIHAacDcbtPMBc5U4ijg2aJuTzAzawa5dR9FRLuk84Cb\nSHZJvTwilkianT4+B5hHsjvqcpJdUs/Oqx4zM+tZrtsUImIeyRd/tm1O5nYAH8uzBjMz6z0fMmtm\nZl0cCmZm1sWhYGZmXRwKZmbWpd+NkiqpDVi5k08fCzy9C8vZlZq1Nte1Y5q1Lmje2lzXjtnZuvaN\niHE9TdTvQuHlkLSgN0PHNkKz1ua6dkyz1gXNW5vr2jF51+XuIzMz6+JQMDOzLkULhcsaXUAdzVqb\n69oxzVoXNG9trmvH5FpXobYpmJlZfUVbUzAzszocCmZm1qUwoSDpREnLJC2XdH4D65gs6b8l3S9p\niaRPpu0XSFotaVF6ObkBtT0i6d709RekbaMl3SzpwfR6jwbUdWBmuSyStEHS3zVimUm6XNJTku7L\ntNVcRpI+l37mlkk6oY/r+qakv0q6R9KvJbWm7VMkbckstzm155xLXTX/bn21vOrU9vNMXY9IWpS2\n98kyq/P90HefsYjY7S8kQ3c/BOwHDAQWA9MbVMt44DXp7RHAA8B04ALgHxq8nB4BxnZr+wZwfnr7\nfODrTfC3fALYtxHLDHg98Brgvp6WUfp3XQwMAqamn8FyH9Z1PNCS3v56pq4p2ekasLyq/t36cnnV\nqq3b4xcCX+zLZVbn+6HPPmNFWVM4ElgeESsiYhtwNTCrEYVExOMRcXd6+zlgKcl5qZvVLOCH6e0f\nAu9oYC0AxwEPRcTOHtX+skTE7cAz3ZprLaNZwNURsTUiHiY5b8iRfVVXRPwuItrTu3eSnNmwT9VY\nXrX02fLqqTZJAt4D/Cyv169RU63vhz77jBUlFCYCj2Xur6IJvoglTQFeDdyVNn08XdW/vBHdNCSn\nkL9F0kJJ56Zte8ULZ8N7AtirAXVlncaL/1Ebvcyg9jJqps/dh4DfZu5PTbtBbpN0TAPqqfZ3a6bl\ndQzwZEQ8mGnr02XW7fuhzz5jRQmFpiNpOHAN8HcRsQH4Lkn31uHA4ySrrn3tdRFxOHAS8DFJr88+\nGMn6asP2YVZyWte3A79Mm5phmb1Io5dRNZI+D7QDP02bHgf2Sf/WnwaukjSyD0tqur9bFe/jxT8+\n+nSZVfl+6JL3Z6woobAamJy5PyltawhJA0j+4D+NiGsBIuLJiOiIiE7ge+S42lxLRKxOr58Cfp3W\n8KSk8Wnd44Gn+rqujJOAuyPiSWiOZZaqtYwa/rmTdBbwVuD09MuEtKthbXp7IUk/9AF9VVOdv1vD\nlxeApBbgncDPK219ucyqfT/Qh5+xooTCfGCapKnpr83TgLmNKCTtq/wBsDQi/i3TPj4z2SnAfd2f\nm3NdwySNqNwm2Uh5H8ly+mA62QeB6/uyrm5e9Out0csso9YymgucJmmQpKnANOAvfVWUpBOBzwBv\nj4jNmfZxksrp7f3Sulb0YV21/m4NXV4ZbwL+GhGrKg19tcxqfT/Ql5+xvLemN8sFOJlkS/5DwOcb\nWMfrSFb97gEWpZeTgR8D96btc4HxfVzXfiR7MSwGllSWETAG+D3wIHALMLpBy20YsBYYlWnr82VG\nEkqPA9tJ+m8/XG8ZAZ9PP3PLgJP6uK7lJP3Nlc/ZnHTad6V/40XA3cDb+riumn+3vlpetWpL268E\nZnebtk+WWZ3vhz77jHmYCzMz61KU7iMzM+sFh4KZmXVxKJiZWReHgpmZdXEomJlZF4eCNQ1Jf0qv\np0h6/y6e9z9We628SHqHpC/mNO9/7HmqHZ7nIZKu3NXztf7Hu6Ra05F0LMkomm/dgee0xAuDv1V7\nfGNEDN8V9fWynj+RHDT29Mucz0veV17vRdItwIci4tFdPW/rP7ymYE1D0sb05teAY9LBxz4lqazk\n3ADz00HUPpJOf6ykP0iaC9yftl2XDui3pDKon6SvAUPS+f00+1pKfFPSfUrOJfHezLxvlfQrJeck\n+Gl6tCmSvqZkvPt7JH2ryvs4ANhaCQRJV0qaI2mBpAckvTVt7/X7ysy72ns5Q9Jf0rZLM0febpT0\nVUmLJd0paa+0/d3p+10s6fbM7H9DcrS/FVmeRwz64suOXICN6fWxwA2Z9nOBL6S3BwELSMaOPxbY\nBEzNTDs6vR5CMnzCmOy8q7zWu4CbSc7TsBfwKMmY9scCz5KMJVMC/kxytOkYkiNHK2vZrVXex9nA\nhZn7VwI3pvOZRnL07OAdeV/Vak9vv5Lky3xAev8S4Mz0dpAeeUsyHn/lte4FJnavH/jfwG8a/Tnw\npbGXlt6Gh1kDHQ8cKunU9P4oki/XbcBfIhlHvuITkk5Jb09Op1tbZ96vA34WER0kg47dBhwBbEjn\nvQpAyRm4ppCcl+B54AeSbgBuqDLP8UBbt7ZfRDIA3IOSVgAH7eD7quU44LXA/HRFZggvDJa2LVPf\nQuDN6e0/AldK+gVw7Quz4ilgQi9e03ZjDgXrDwR8PCJuelFjsu1hU7f7bwKOjojNkm4l+UW+s7Zm\nbneQnMWsXdKRJF/GpwLnAX/T7XlbSL7gs7pvvAt6+b56IOCHEfG5Ko9tj4jK63aQ/r9HxGxJM4G3\nAAslvTaSEUAHp7VbgXmbgjWj50hORVhxE/BRJUMKI+mAdCTX7kYB69JAOAg4KvPY9srzu/kD8N60\nf38cySkaa44yqWSc+1ERMQ/4FHBYlcmWAq/o1vZuSSVJ+5MMPrhsB95Xd9n38nvgVEl7pvMYLWnf\nek+WtH9E3BURXyRZo6kMvXwAjRtp1pqE1xSsGd0DdEhaTNIf/22Srpu70429bVQ/LeiNwGxJS0m+\ndO/MPHYZcI+kuyPi9Ez7r4GjSUaHDeAzEfFEGirVjACulzSY5Ff6p6tMcztwoSRlfqk/ShI2I0lG\n4Hxe0vdwsVKcAAAAiUlEQVR7+b66e9F7kfQF4HeSSiQjfn4MqHe60m9KmpbW//v0vQO8Efh/vXh9\n2415l1SzHEj6NslG21vS/f9viIhfNbismiQNAm4jOftezV17bffn7iOzfPwrMLTRReyAfYDzHQjm\nNQUzM+viNQUzM+viUDAzsy4OBTMz6+JQMDOzLg4FMzPr8v8BypcVCszTFacAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f732c72c978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 1.0\n",
      "Validation Accuracy: 0.9684\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train_flatten, y_train_one_hot, X_val_flatten, y_val_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Start the session to compute the tensorflow graph\n",
    "with tf.Session() as sess:\n",
    "    n_x = 784\n",
    "    n_y = 10\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    Z2 = forward_propagation(X, parameters)\n",
    "    # Calculate the correct predictions\n",
    "    correct_prediction = tf.equal(tf.argmax(Z2), tf.argmax(Y))\n",
    "\n",
    "    # Calculate accuracy on the test set\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "    print (\"Test Accuracy:\", accuracy.eval({X: X_test_flatten, Y: y_test_one_hot}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
